{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow依赖于一个高效的C++后端来进行计算。与后端的这个连接叫做session。\n",
    "#一般而言，使用TensorFlow程序的流程是先创建一个图，然后在session中启动它。\n",
    "\n",
    "# 这里，我们使用更加方便的InteractiveSession类。\n",
    "#通过它，你可以更加灵活地构建你的代码。它能让你在运行图的时候，插入一些计算图，这些计算图是由某些操作(operations)构成的。\n",
    "#这对于工作在交互式环境中的人们来说非常便利，比如使用IPython。如果你没有使用InteractiveSession，那么你需要在启动session之前构建整个计算图，然后启动该计算图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#计算图\n",
    "\n",
    "# 为了在Python中进行高效的数值计算，我们通常会使用像NumPy一类的库，将一些诸如矩阵乘法的耗时操作在Python环境的外部来计算，这些计算通常会通过其它语言并用更为高效的代码来实现。\n",
    "\n",
    "# 但遗憾的是，每一个操作切换回Python环境时仍需要不小的开销。如果你想在GPU或者分布式环境中计算时，这一开销更加可怖，这一开销主要可能是用来进行数据迁移。\n",
    "\n",
    "# TensorFlow也是在Python外部完成其主要工作，但是进行了改进以避免这种开销。\n",
    "# 其并没有采用在Python外部独立运行某个耗时操作的方式，而是先让我们描述一个交互操作图，然后完全将其运行在Python外部。这与Theano或Torch的做法类似。\n",
    "\n",
    "#因此，Python代码的目的是用来构建这个可以在外部运行的计算图，以及安排计算图的哪一部分应该被运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 加载MNIST数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建一个多层卷积网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 在MNIST上只有91%正确率，此次我们用一个稍微复杂的模型：卷积神经网络来改善效果。这会达到大概99.2%的准确率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 设置按需使用GPU\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = False\n",
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 定义模型 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 为输入图像和目标输出类别创建节点，来开始构建计算图。\n",
    "# x和y并不是特定的值，相反，他们都只是一个占位符，可以在TensorFlow运行某一计算时根据该占位符输入具体的值。\n",
    "x = tf.placeholder(\"float\", shape=[None, 784])\n",
    "y_ = tf.placeholder(\"float\", shape=[None, 10])\n",
    "\n",
    "# 为模型定义权重W和偏置b。\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "# 变量需要通过seesion初始化后，才能在session中使用。这一初始化步骤为，为初始值指定具体值（本例当中是全为零），并将其分配给每个变量,可以一次性为所有变量完成此操作。\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# 我们把向量化后的图片x和权重矩阵W相乘，加上偏置b，然后计算每个分类的softmax概率值。\n",
    "y = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "# 为训练过程指定最小化误差用的损失函数，我们的损失函数是目标类别和预测类别之间的交叉熵。\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "\n",
    "# 我们已经定义好模型和训练用的损失函数，那么用TensorFlow进行训练就很简单了。因为TensorFlow知道整个计算图，它可以使用自动微分法找到对于各个变量的损失的梯度值。\n",
    "# TensorFlow有大量内置的优化算法 这个例子中，我们用最速下降法让交叉熵下降，步长为0.01.\n",
    "# 用来往计算图上添加一个新操作，其中包括计算梯度，计算每个参数的步长变化，并且计算出新的参数值。\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "for i in range(1000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "# 每一步迭代，都会加载50个训练样本，然后执行一次train_step，并通过feed_dict将x 和 y_张量占位符用训练训练数据替代。\n",
    "# 在计算图中，可以用feed_dict来替代任何张量，并不仅限于替换占位符。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 权重初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 为了创建这个模型，我们需要创建大量的权重和偏置项。\n",
    "# 这个模型中的权重在初始化时应该加入少量的噪声来打破对称性以及避免0梯度。\n",
    "# 由于我们使用的是ReLU神经元，因此比较好的做法是用一个较小的正数来初始化偏置项，以避免神经元节点输出恒为0的问题（dead neurons）。\n",
    "# 为了不在建立模型的时候反复做初始化操作，我们定义两个函数用于初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 卷积和池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TensorFlow在卷积和池化上有很强的灵活性。我们怎么处理边界？步长应该设多大？\n",
    "# 在这个实例里，我们会一直使用vanilla版本。我们的卷积使用1步长（stride size），0边距（padding size）的模板，保证输出和输入是同一个大小。\n",
    "# 我们的池化用简单传统的2x2大小的模板做max pooling。为了代码更简洁，我们把这部分抽象成一个函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 知识点：卷积\n",
    "# tf.nn.conv2d是TensorFlow里面实现卷积的函数，这是搭建卷积神经网络比较核心的一个方法，非常重要。\n",
    "# tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, name=None)\n",
    "# 除去name参数用以指定该操作的name，与方法有关的一共五个参数：\n",
    "# (1). 第一个参数input：指需要做卷积的输入图像，它要求是一个Tensor，具有[batch, in_height, in_width, in_channels]这样的shape，\n",
    "# 具体含义是[训练时一个batch的图片数量, 图片高度, 图片宽度, 图像通道数]，注意这是一个4维的Tensor，要求类型为float32和float64其中之一\n",
    "# (2). 第二个参数filter：相当于CNN中的卷积核，它要求是一个Tensor，具有[filter_height, filter_width, in_channels, out_channels]这样的shape.\n",
    "# 具体含义是[卷积核的高度，卷积核的宽度，图像通道数，卷积核个数]，要求类型与参数input相同，有一个地方需要注意，第三维in_channels，就是参数input的第四维\n",
    "# (3). 第三个参数strides：卷积时在图像每一维的步长，这是一个一维的向量，长度4\n",
    "# (4). 第四个参数padding：string类型的量，只能是\"SAME\",\"VALID\"其中之一，这个值决定了不同的卷积方式（后面会介绍）\n",
    "# (5). 第五个参数：use_cudnn_on_gpu:bool类型，是否使用cudnn加速，默认为true\n",
    "# 结果返回一个Tensor，这个输出，就是我们常说的feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 第一层卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 现在我们可以开始实现第一层了。\n",
    "# 它由一个卷积接一个max pooling完成。\n",
    "# 卷积在每个5x5的patch中算出32个特征。卷积的权重张量形状是[5, 5, 1, 32]，前两个维度是patch的大小，接着是输入的通道数目，最后是输出的通道数目。 \n",
    "# 而对于每一个输出通道都有一个对应的偏置量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 为了用这一层，我们把x变成一个4d向量，其第2、第3维对应图片的宽、高，\n",
    "# 最后一维代表图片的颜色通道数(因为是灰度图所以这里的通道数为1，如果是rgb彩色图，则为3)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We then convolve x_image with the weight tensor, add the bias, apply the ReLU function, and finally max pool. \n",
    "# 我们把x_image和权值向量进行卷积，加上偏置项，然后应用ReLU激活函数，最后进行max pooling。\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.第二层卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 为了构建一个更深的网络，我们会把几个类似的层堆叠起来。第二层中，每个5x5的patch会得到64个特征。\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.密集连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 现在，图片尺寸减小到7x7，我们加入一个有1024个神经元的全连接层，用于处理整个图片。\n",
    "# 我们把池化层输出的张量reshape成一些向量，乘上权重矩阵，加上偏置，然后对其使用ReLU。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 为了减少过拟合，我们在输出层之前加入dropout。\n",
    "# 用一个placeholder来代表一个神经元的输出在dropout中保持不变的概率。\n",
    "# 在训练过程中启用dropout，在测试过程中关闭dropout。 \n",
    "# TensorFlow的tf.nn.dropout操作除了可以屏蔽神经元的输出外，还会自动处理神经元输出值的scale。所以用dropout的时候可以不用考虑scale。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.输出层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 最后，我们添加一个softmax层\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 训练和评估模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 为了进行训练和评估，我们使用与之前简单的单层SoftMax神经网络模型几乎相同的一套代码.\n",
    "# 此次，用更加复杂的ADAM优化器来做梯度最速下降，在feed_dict中加入额外的参数keep_prob来控制dropout比例。然后每100次迭代输出一次日志。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.1\n",
      "step 100, training accuracy 0.82\n",
      "step 200, training accuracy 0.9\n",
      "step 300, training accuracy 0.88\n",
      "step 400, training accuracy 0.92\n",
      "step 500, training accuracy 0.9\n",
      "step 600, training accuracy 0.94\n",
      "step 700, training accuracy 0.94\n",
      "step 800, training accuracy 0.96\n",
      "step 900, training accuracy 0.92\n",
      "step 1000, training accuracy 0.92\n",
      "step 1100, training accuracy 1\n",
      "step 1200, training accuracy 1\n",
      "step 1300, training accuracy 1\n",
      "step 1400, training accuracy 0.98\n",
      "step 1500, training accuracy 0.96\n",
      "step 1600, training accuracy 1\n",
      "step 1700, training accuracy 0.96\n",
      "step 1800, training accuracy 0.98\n",
      "step 1900, training accuracy 0.98\n",
      "step 2000, training accuracy 1\n",
      "step 2100, training accuracy 0.98\n",
      "step 2200, training accuracy 1\n",
      "step 2300, training accuracy 0.94\n",
      "step 2400, training accuracy 0.98\n",
      "step 2500, training accuracy 0.98\n",
      "step 2600, training accuracy 0.96\n",
      "step 2700, training accuracy 0.96\n",
      "step 2800, training accuracy 1\n",
      "step 2900, training accuracy 0.98\n",
      "step 3000, training accuracy 0.94\n",
      "step 3100, training accuracy 0.96\n",
      "step 3200, training accuracy 0.98\n",
      "step 3300, training accuracy 1\n",
      "step 3400, training accuracy 1\n",
      "step 3500, training accuracy 0.98\n",
      "step 3600, training accuracy 0.96\n",
      "step 3700, training accuracy 1\n",
      "step 3800, training accuracy 0.98\n",
      "step 3900, training accuracy 1\n",
      "step 4000, training accuracy 0.98\n",
      "step 4100, training accuracy 0.98\n",
      "step 4200, training accuracy 0.98\n",
      "step 4300, training accuracy 1\n",
      "step 4400, training accuracy 1\n",
      "step 4500, training accuracy 0.92\n",
      "step 4600, training accuracy 0.98\n",
      "step 4700, training accuracy 0.98\n",
      "step 4800, training accuracy 1\n",
      "step 4900, training accuracy 1\n",
      "step 5000, training accuracy 1\n",
      "step 5100, training accuracy 1\n",
      "step 5200, training accuracy 1\n",
      "step 5300, training accuracy 1\n",
      "step 5400, training accuracy 1\n",
      "step 5500, training accuracy 0.96\n",
      "step 5600, training accuracy 0.98\n",
      "step 5700, training accuracy 0.98\n",
      "step 5800, training accuracy 0.98\n",
      "step 5900, training accuracy 0.98\n",
      "step 6000, training accuracy 1\n",
      "step 6100, training accuracy 1\n",
      "step 6200, training accuracy 1\n",
      "step 6300, training accuracy 0.98\n",
      "step 6400, training accuracy 1\n",
      "step 6500, training accuracy 1\n",
      "step 6600, training accuracy 0.96\n",
      "step 6700, training accuracy 1\n",
      "step 6800, training accuracy 0.98\n",
      "step 6900, training accuracy 1\n",
      "step 7000, training accuracy 1\n",
      "step 7100, training accuracy 1\n",
      "step 7200, training accuracy 0.98\n",
      "step 7300, training accuracy 0.98\n",
      "step 7400, training accuracy 0.98\n",
      "step 7500, training accuracy 1\n",
      "step 7600, training accuracy 1\n",
      "step 7700, training accuracy 1\n",
      "step 7800, training accuracy 1\n",
      "step 7900, training accuracy 1\n",
      "step 8000, training accuracy 1\n",
      "step 8100, training accuracy 1\n",
      "step 8200, training accuracy 1\n",
      "step 8300, training accuracy 1\n",
      "step 8400, training accuracy 1\n",
      "step 8500, training accuracy 1\n",
      "step 8600, training accuracy 1\n",
      "step 8700, training accuracy 0.98\n",
      "step 8800, training accuracy 1\n",
      "step 8900, training accuracy 1\n",
      "step 9000, training accuracy 1\n",
      "step 9100, training accuracy 1\n",
      "step 9200, training accuracy 1\n",
      "step 9300, training accuracy 1\n",
      "step 9400, training accuracy 1\n",
      "step 9500, training accuracy 1\n",
      "step 9600, training accuracy 1\n",
      "step 9700, training accuracy 1\n",
      "step 9800, training accuracy 1\n",
      "step 9900, training accuracy 1\n",
      "step 10000, training accuracy 1\n",
      "step 10100, training accuracy 1\n",
      "step 10200, training accuracy 1\n",
      "step 10300, training accuracy 1\n",
      "step 10400, training accuracy 0.98\n",
      "step 10500, training accuracy 1\n",
      "step 10600, training accuracy 1\n",
      "step 10700, training accuracy 1\n",
      "step 10800, training accuracy 1\n",
      "step 10900, training accuracy 1\n",
      "step 11000, training accuracy 1\n",
      "step 11100, training accuracy 1\n",
      "step 11200, training accuracy 1\n",
      "step 11300, training accuracy 1\n",
      "step 11400, training accuracy 1\n",
      "step 11500, training accuracy 1\n",
      "step 11600, training accuracy 1\n",
      "step 11700, training accuracy 1\n",
      "step 11800, training accuracy 0.98\n",
      "step 11900, training accuracy 1\n",
      "step 12000, training accuracy 1\n",
      "step 12100, training accuracy 1\n",
      "step 12200, training accuracy 1\n",
      "step 12300, training accuracy 1\n",
      "step 12400, training accuracy 1\n",
      "step 12500, training accuracy 1\n",
      "step 12600, training accuracy 1\n",
      "step 12700, training accuracy 1\n",
      "step 12800, training accuracy 1\n",
      "step 12900, training accuracy 0.98\n",
      "step 13000, training accuracy 1\n",
      "step 13100, training accuracy 1\n",
      "step 13200, training accuracy 1\n",
      "step 13300, training accuracy 1\n",
      "step 13400, training accuracy 0.96\n",
      "step 13500, training accuracy 1\n",
      "step 13600, training accuracy 1\n",
      "step 13700, training accuracy 1\n",
      "step 13800, training accuracy 1\n",
      "step 13900, training accuracy 1\n",
      "step 14000, training accuracy 1\n",
      "step 14100, training accuracy 1\n",
      "step 14200, training accuracy 1\n",
      "step 14300, training accuracy 1\n",
      "step 14400, training accuracy 1\n",
      "step 14500, training accuracy 0.98\n",
      "step 14600, training accuracy 1\n",
      "step 14700, training accuracy 1\n",
      "step 14800, training accuracy 1\n",
      "step 14900, training accuracy 1\n",
      "step 15000, training accuracy 1\n",
      "step 15100, training accuracy 1\n",
      "step 15200, training accuracy 1\n",
      "step 15300, training accuracy 1\n",
      "step 15400, training accuracy 1\n",
      "step 15500, training accuracy 1\n",
      "step 15600, training accuracy 1\n",
      "step 15700, training accuracy 1\n",
      "step 15800, training accuracy 1\n",
      "step 15900, training accuracy 1\n",
      "step 16000, training accuracy 1\n",
      "step 16100, training accuracy 1\n",
      "step 16200, training accuracy 0.98\n",
      "step 16300, training accuracy 1\n",
      "step 16400, training accuracy 1\n",
      "step 16500, training accuracy 1\n",
      "step 16600, training accuracy 1\n",
      "step 16700, training accuracy 1\n",
      "step 16800, training accuracy 1\n",
      "step 16900, training accuracy 1\n",
      "step 17000, training accuracy 1\n",
      "step 17100, training accuracy 1\n",
      "step 17200, training accuracy 1\n",
      "step 17300, training accuracy 0.98\n",
      "step 17400, training accuracy 1\n",
      "step 17500, training accuracy 1\n",
      "step 17600, training accuracy 1\n",
      "step 17700, training accuracy 0.98\n",
      "step 17800, training accuracy 1\n",
      "step 17900, training accuracy 1\n",
      "step 18000, training accuracy 1\n",
      "step 18100, training accuracy 1\n",
      "step 18200, training accuracy 1\n",
      "step 18300, training accuracy 1\n",
      "step 18400, training accuracy 1\n",
      "step 18500, training accuracy 0.98\n",
      "step 18600, training accuracy 1\n",
      "step 18700, training accuracy 1\n",
      "step 18800, training accuracy 1\n",
      "step 18900, training accuracy 1\n",
      "step 19000, training accuracy 1\n",
      "step 19100, training accuracy 1\n",
      "step 19200, training accuracy 1\n",
      "step 19300, training accuracy 1\n",
      "step 19400, training accuracy 1\n",
      "step 19500, training accuracy 1\n",
      "step 19600, training accuracy 1\n",
      "step 19700, training accuracy 1\n",
      "step 19800, training accuracy 1\n",
      "step 19900, training accuracy 1\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for i in range(20000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\" % accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 下面改成了 test 也用 mini_batch 的形式， 显存只用了 529M,所以还是很成功的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training acc 0.08\n",
      "step 500, training acc 0.94\n",
      "step 1000, training acc 0.98\n",
      "step 1500, training acc 0.98\n",
      "step 2000, training acc 1\n",
      "step 2500, training acc 1\n",
      "step 3000, training acc 1\n",
      "step 3500, training acc 1\n",
      "step 4000, training acc 1\n",
      "step 4500, training acc 1\n",
      "testing step 20, test_acc_sum 19.64\n",
      "testing step 40, test_acc_sum 39.5\n",
      "testing step 60, test_acc_sum 59.26\n",
      "testing step 80, test_acc_sum 78.94\n",
      "testing step 100, test_acc_sum 98.75\n",
      " test_accuracy 0.9875\n"
     ]
    }
   ],
   "source": [
    "# 题外话：在做这个例子的过程中遇到过：资源耗尽的错误，为什么？\n",
    "# -> 因为之前每次做 train_acc  的时候用了全部的 55000 张图，显存爆了.\n",
    "\n",
    "# 1.损失函数：cross_entropy\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n",
    "# 2.优化函数：AdamOptimizer\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# 3.预测准确结果统计\n",
    "#　预测值中最大值（１）即分类结果，是否等于原始标签中的（１）的位置。argmax()取最大值所在的下标\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))  \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# 如果一次性来做测试的话，可能占用的显存会比较多，所以测试的时候也可以设置较小的batch来看准确率\n",
    "test_acc_sum = tf.Variable(0.0)\n",
    "batch_acc = tf.placeholder(tf.float32)\n",
    "new_test_acc_sum = tf.add(test_acc_sum, batch_acc)\n",
    "update = tf.assign(test_acc_sum, new_test_acc_sum)\n",
    "\n",
    "# 定义了变量必须要初始化，或者下面形式\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# 或者某个变量单独初始化 如：\n",
    "# x.initializer.run()\n",
    "\n",
    "# 训练\n",
    "for i in range(5000):\n",
    "    X_batch, y_batch = mnist.train.next_batch(batch_size=50)\n",
    "    if i % 500 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x: X_batch, y_: y_batch, keep_prob: 1.0})\n",
    "        print(\"step %d, training acc %g\" % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: X_batch, y_: y_batch, keep_prob: 0.5})  \n",
    "\n",
    "# 全部训练完了再做测试，batch_size=100\n",
    "for i in range(100): \n",
    "    X_batch, y_batch = mnist.test.next_batch(batch_size=100)\n",
    "    test_acc = accuracy.eval(feed_dict={x: X_batch, y_: y_batch, keep_prob: 1.0})\n",
    "    update.eval(feed_dict={batch_acc: test_acc})\n",
    "    if (i+1) % 20 == 0:\n",
    "        print(\"testing step %d, test_acc_sum %g\" % (i+1, test_acc_sum.eval()))\n",
    "print(\" test_accuracy %g\" % (test_acc_sum.eval() / 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
